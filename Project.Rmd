---
title: "Week 4 project - Getting and Cleaning Data"
author: "Camilla Jensen"
date: "October 21, 2016"
output: word_document
---
This codebook explains step by step how the data was created and binds together all the files and scripts that were used to complete the project assignment. 

It is therefore in principle the combination of all the other submitted files and the readme file. The list of variables, their explanations and measurement is reported at the end of the codebook. The scripts are embedded in the codebook as well.  In some sense the readme file becomes superfluous. Hence my readme file is really short and mainly serves to give proper reference to the data source.
---
1.SCRIPT WITH EXPLANATIONS

First we need to download and unzip the dataset (must be connected to Internet for this step to work):
```{r}
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile="HARUSD.zip") 
```

Close all connections and unzip the folder:
```{r}

unzip(zipfile="HARUSD.zip")
```

Now we can see the same dataset in the local environment (my documents folder) as we can see online or by just downloading it to the PC and it got into the right archive or folder on its own and it looks exactly the way it should and is in the folder named "UCI HAR Dataset". 

From this 'raw' dataset we have to read in any relevant part to solve the assignment.

The README file contains a lot of information about this. We learn that test and train are subsets of the full subject sample, e.g. 30/70 division of trial subjects into these two groups. This means that we need to stack the two subsets into one file rather than merging them via any common id per se. In other words the subjectids are not overlapping in this case so some of the 30 subjects are tried out in the train part of the dataset and the others in the test part. So for this procedure we have to use the rbind command (e.g. to stack the data). 

First we need to read in all the files as data tables. X_train and X_test are really the essential files as they contain all the data, while y_train and y_test hold the key to the activity codes of which there are 6 and link these codes to  the actual descriptors. Similarly, subject_train and subject_test contain the keys to the subject ids of which there are 30.

First I read in all the labelling files using the following commands:
```{r}
headers <- read.table ("UCI HAR Dataset/features.txt")
activity <- read.table ("UCI HAR Dataset/activity_labels.txt")
subjectid_train <- read.table("UCI HAR Dataset/train/subject_train.txt")
subjectid_test <- read.table("UCI HAR Dataset/test/subject_test.txt")
```

Now I read in the actual data files:
```{r}
X_train <- read.table("UCI HAR Dataset/train/X_train.txt")
X_test <- read.table("UCI HAR Dataset/test/X_test.txt")
```

And finally the activity id's that connect the dots:
```{r}
y_train <- read.table("UCI HAR Dataset/train/y_train.txt")
y_test <- read.table("UCI HAR Dataset/test/y_test.txt")
```

We have read in a totality of 8 files and it can also be verified under Data in the Global Environment. Here we now see the following data read into r-studio:

activity, 6 obs of 2 vars
headers, 561 obs of 2 vars
subjectid_test, 2947 obs of 1 var
subjectid_train, 7352 obs of 1 var
X_test, 2947 obs of 561 vars
X_train, 7352 obs of 561 vars
y_test, 2947 obs of 1 var
y_train, 7352 obs of 1 var

These datafiles must be merged to get to the full dataset. We start by assigning the 561 obs in header onto the X_test and X_train datasets as these 561 obs are the key to understanding what lies under the 561 vars in actual datasets:
```{r}
colnames(X_train) <- headers[ ,2]
colnames(X_test) <- headers[ ,2]
```

Then we have to assign the header activitycode to the 2947 and 7352 obs in the two datasets. This is the 1 var in the y_test and y_train datatset and we have to assign the header subjectid to the 1 var in the subject_id test and the subject_id train datatables: 
```{r}
colnames(y_train) <- "activitycode"
colnames(y_test) <- "activitycode"
colnames(subjectid_test) <- "subjectid"
colnames(subjectid_train) <- "subjectid"
```

Finally we need to assign the same header to the activitylabels file and thereby get access to the descriptor for the 6 activity groups (but it will only be attached ot the full dataset as the last step before delivering the data because it is string and will disappear in the later aggregations):
```{r}
colnames(activity) <- c("activitycode", "activitytype")
```

Now we can first merge all the info for the train and test groups respectively, and then finally combine them into a full datast using rbind:
```{r}
train <- cbind(y_train, subjectid_train, X_train)
test <- cbind(y_test, subjectid_test, X_test)
fullset <- rbind(train, test)
```

Looking at the Data files on the right hand side in R studio we can see that train and test now have 563 vars instead of the original 561 vars as we have added the activitycodes and subjectids to the actual data. Finally the fullset combines the two subsamples into one and has the correct sum of observations e.g. 2,947+7,352=10,299 obs. Checking with head and tail commands everything looks normal in the dataset and we can see the activitycodes and subjectids followed by all the other variables.

The next step is to select only a portion of the fullset, namely all variables that contain variable means m and standard deviations sd (and assumedly not include the meanFreq as it is a different kind of stats var). We also want to keep the activitycodes and subjectids. We can use the grepl function which can search for patterns in the text, hence we want to extract anything from the fullset where the following is true and afterwards apply this selectdata function to retrieve the relevant portion of the fullset to get the fullset_ms (selective part only containing mean and sd values):
```{r}
COLS <- colnames(fullset)
selectdata <- (grepl("activitycode", COLS) | grepl("subjectid", COLS) | grepl("mean()..", COLS) & !grepl("-meanFreq..", COLS) | grepl("std()...", COLS))
fullset_ms <-fullset[ ,selectdata==TRUE]
```

Finally we need to make the summary dataset from the fullset_ms file where this data is now summarised in a more condensed form by subjectid and activitycodes. 

We also have to make sure the data is properly labelled with the description of the activitycodes using the string variable. Here the problem might be that summarizing the data returns numeric values for the string labels. Hence we wait to add the labels to the very last step before writing the final dataset as a textfile:
```{r}
finaldata <- aggregate(. ~subjectid + activitycode, fullset_ms, mean)
finaldata <- merge (activity, finaldata, by="activitycode")
write.table(finaldata, "finaldata.txt", row.names=FALSE)
```

The final dataset has 180 observations (e.g. 6 activities x 30 subjects = 180 obs) and there is now a totality of only 60 variables (as described next with the metadata file).

---
2. METADATA

First we can create a list of the vars for the metadata to copy over to the text:
```{r}
str(finaldata)

```

The trimmed output is copied here below (for exact definition of the vars with respect to more technical features of the dataset see also the Feature selection file from the authors which is copied in towards the end of the file). It is not entirely clear from the documentation given what is the unit of measurement neither of time nor frequency variables, so I guess for time it is seconds, but for frequency it could be either 50, 20 or 0.3 hz as I have no full insight into how those filters work:

Variable:                     Class and units:
activitycode                  Integer w/ 6 levels 1 through 6
activitytype                  Factor w/ 6 levels "LAYING","SITTING"etc.
subjectid                     Integer w/ 30 subjects 1 through 30
tBodyAcc-mean()-X             Numeric, sec (time)
tBodyAcc-mean()-Y             Numeric, sec
tBodyAcc-mean()-Z             Numeric, sec
tBodyAcc-std()-X              Numeric, sec
tBodyAcc-std()-Y              Numeric, sec
tBodyAcc-std()-Z              Numeric, sec
tGravityAcc-mean()-X          Numeric, sec
tGravityAcc-mean()-Y          Numeric, sec
tGravityAcc-mean()-Z          Numeric, sec
tGravityAcc-std()-X           Numeric, sec
tGravityAcc-std()-Y           Numeric, sec
tGravityAcc-std()-Z           Numeric, sec
tBodyAccJerk-mean()-X         Numeric, sec
tBodyAccJerk-mean()-Y         Numeric, sec
tBodyAccJerk-mean()-Z         Numeric, sec 
tBodyAccJerk-std()-X          Numeric, sec
tBodyAccJerk-std()-Y          Numeric, sec
tBodyAccJerk-std()-Z          Numeric, sec
tBodyGyro-mean()-X            Numeric, sec
tBodyGyro-mean()-Y            Numeric, sec
tBodyGyro-mean()-Z            Numeric, sec
tBodyGyro-std()-X             Numeric, sec
tBodyGyro-std()-Y             Numeric, sec
tBodyGyro-std()-Z             Numeric, sec
tBodyGyroJerk-mean()-X        Numeric, sec
tBodyGyroJerk-mean()-Y        Numeric, sec
tBodyGyroJerk-mean()-Z        Numeric, sec
tBodyGyroJerk-std()-X         Numeric, sec
tBodyGyroJerk-std()-Y         Numeric, sec
tBodyGyroJerk-std()-Z         Numeric, sec
tBodyAccMag-mean()            Numeric, sec
tGravityAccMag-mean()         Numeric, sec
tBodyAccJerkMag-mean()        Numeric, sec
tBodyGyroMag-mean()           Numeric, sec
tBodyGyroJerkMag-mean()       Numeric, sec
fBodyAcc-mean()-X             Numeric, hz (frequency, either 50, 20 or 0.3??)
fBodyAcc-mean()-Y             Numeric, hz
fBodyAcc-mean()-Z             Numeric, hz
fBodyAcc-std()-X              Numeric, hz
fBodyAcc-std()-Y              Numeric, hz
fBodyAcc-std()-Z              Numeric, hz
fBodyAccJerk-mean()-X         Numeric, hz
fBodyAccJerk-mean()-Y         Numeric, hz
fBodyAccJerk-mean()-Z         Numeric, hz
fBodyAccJerk-std()-X          Numeric, hz
fBodyAccJerk-std()-Y          Numeric, hz
fBodyAccJerk-std()-Z          Numeric, hz
fBodyGyro-mean()-X            Numeric, hz
fBodyGyro-mean()-Y            Numeric, hz
fBodyGyro-mean()-Z            Numeric, hz
fBodyGyro-std()-X             Numeric, hz
fBodyGyro-std()-Y             Numeric, hz
fBodyGyro-std()-Z             Numeric, hz
fBodyAccMag-mean()            Numeric, hz
fBodyBodyAccJerkMag-mean()    Numeric, hz
fBodyBodyGyroMag-mean()       Numeric, hz
fBodyBodyGyroJerkMag-mean()   Numeric, hz

Feature Selection 
=================

The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 

Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). 

These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.

tBodyAcc-XYZ
tGravityAcc-XYZ
tBodyAccJerk-XYZ
tBodyGyro-XYZ
tBodyGyroJerk-XYZ
tBodyAccMag
tGravityAccMag
tBodyAccJerkMag
tBodyGyroMag
tBodyGyroJerkMag
fBodyAcc-XYZ
fBodyAccJerk-XYZ
fBodyGyro-XYZ
fBodyAccMag
fBodyAccJerkMag
fBodyGyroMag
fBodyGyroJerkMag

The set of variables that were estimated from these signals are: 

mean(): Mean value
std(): Standard deviation
mad(): Median absolute deviation 
max(): Largest value in array
min(): Smallest value in array
sma(): Signal magnitude area
energy(): Energy measure. Sum of the squares divided by the number of values. 
iqr(): Interquartile range 
entropy(): Signal entropy
arCoeff(): Autorregresion coefficients with Burg order equal to 4
correlation(): correlation coefficient between two signals
maxInds(): index of the frequency component with largest magnitude
meanFreq(): Weighted average of the frequency components to obtain a mean frequency
skewness(): skewness of the frequency domain signal 
kurtosis(): kurtosis of the frequency domain signal 
bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.
angle(): Angle between to vectors.

Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:

gravityMean
tBodyAccMean
tBodyAccJerkMean
tBodyGyroMean
tBodyGyroJerkMean

The complete list of variables of each feature vector is available in 'features.txt'
